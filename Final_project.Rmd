---
title: "Practical machine learning project"
output: html_document
---
## Preparation

In order to conduct this exercise we need to choose the working directory and select some packages that will help us do the analysis. In order the results to be reproduiable we also set a seed.
```{r}
rm (list = ls ())
setwd("~/Work/Cursos/Coursera Applied Machine learning/Proyecto")
library(caret)
library(AppliedPredictiveModeling)
library(rattle)
library(rpart)
library(randomForest)
set.seed(1000)
```
##Data obtention

We automatically download the training data and testing data from the urls provided:
```{r}
fileURL1<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
if(!file.exists("pml-training.csv"))
{
  download.file(fileURL1,destfile="pml-training.csv",method="curl")
  dateDownloaded_Training <- date()
}

fileURL2<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
if(!file.exists("pml-testing.csv"))
{
  download.file(fileURL2,destfile="pml-training.csv",method="curl")
  dateDownloaded_Testing <- date()
}
```
We read the two datasets. They contain missing values. We make sure we read them correctly
```{r}
training <- read.csv("pml-training.csv", na.strings=c("NA","#DIV/0!",""))
testing <- read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!",""))
```

We partionate the training data to perform cross validation. 60% of data for training and 40% for testing
```{r}
trainIndex <- createDataPartition(y= training$classe, p=0.6, list=FALSE)
subset_training <- training[trainIndex,]
subset_testing <- training[-trainIndex,]
```

##Cleaning data
Missing values: We remove those numeric variables in the training set with many missing values. 
Those variables that have more than 60% of the data missing are removed from the dataset.

```{r}
a <-sapply(subset_training, function(x) sum(is.na(x))>round(0.6*dim(subset_training)[1]))
clean_training <- training[a==FALSE]
```
We check if there are still missing values to handle
```{r}
sum(is.na(clean_training))
```
We could eliminate summary variables like those starting by std but these have already been 
eliminated in the previous step because they had many missing values.

We eliminate variables that do not provide valuable information:
```{r}
clean_training <- clean_training[ , -which(names(clean_training) %in% c("num_window","X","user_name","raw_timestamp_part_1","raw_timestamp_part_2","cvtd_timestamp", "new_window"))]
```

Now we make the same transformations performed in the training set in the testing datasets

```{r}
index1 <- colnames(clean_training)
index2 <- colnames(clean_training[, -53]) #we remove the classe column 
clean_subset_testing <- subset_testing[,index1]
testing <- testing[index2]
```
##Training Machine Learning models

We train a decision tree:
```{r}
modFitDT <- rpart(classe ~ ., data=clean_training, method="class")
fancyRpartPlot(modFitDT)
```

We make predictions with the testing data sets 
```{r}
prediction2 <- predict(modFitDT, clean_subset_testing, type = "class")
```
And obtain the confusion Matrix.
```{r}
confusionMatrix(prediction2, clean_subset_testing$classe)
```
We observe that the accuracy is 0.75 (75%) in the testing subset. Therefore the out of sample error will be 1- accuracy = 0.2489 (25%). These values are not very good. We train a random forest and see if we improve it.

```{r}
modFitRF <- randomForest(classe ~. , data=clean_training)
prediction4 <- predict(modFitRF, clean_training, type = "class")
confusionMatrix(prediction4, clean_training$classe)
```
We test it in the testing subset
```{r}
prediction5 <- predict(modFitRF, clean_subset_testing, type = "class")
confusionMatrix(prediction5, clean_subset_testing$classe)
```
We see that the results are much better with Random Forest than with a decision tree. We obtain now 100% accuracy and 0% out of sample error.

We make predictions in the testing set
```{r}
prediction6 <- predict(modFitRF, testing, type = "class")
```
We show the results:
```{r}
prediction6 
```

And write the prediction results of the 20 cases of the testing test into 20 different files for submission.

```{r}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(as.character(prediction6))

```
The results after submission are 100% accurate.
